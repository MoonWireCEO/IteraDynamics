name: ML Improvement Testing

permissions:
  contents: read
  actions: read

on:
  workflow_dispatch:
    inputs:
      approach:
        description: "Which ML improvement approach to test"
        required: true
        type: choice
        options:
          - "1_regime_filter"
          - "2_extended_data"
          - "3_simple_lr"
          - "4_per_regime"
          - "all_approaches"
      symbols:
        description: "Symbols to test (comma-separated)"
        required: false
        default: "SPY,QQQ"
      lookback_days:
        description: "Days of training data (180, 365, etc.)"
        required: false
        default: "180"
      n_splits:
        description: "Number of walk-forward folds (3, 5, 7, etc.)"
        required: false
        default: "3"
      enable_social:
        description: "Enable social features (Reddit sentiment)"
        required: false
        type: boolean
        default: false
      horizon_h:
        description: "Prediction horizon (hours ahead to predict)"
        required: false
        type: choice
        options:
          - "1"
          - "3"
          - "6"
        default: "1"
      social_smoothing:
        description: "Social feature smoothing window (hours) - lower = more sensitive"
        required: false
        type: choice
        options:
          - "1"
          - "3"
          - "6"
        default: "3"
      burst_threshold:
        description: "Burst detection sensitivity (Z-score) - lower = more sensitive"
        required: false
        type: choice
        options:
          - "1.5"
          - "2.0"
          - "2.5"
        default: "2.0"
      btc_model:
        description: "ML model for SPY"
        required: false
        type: choice
        options:
          - "hybrid"
          - "logreg"
          - "gb"
          - "hgb"
        default: "hybrid"
      eth_model:
        description: "ML model for QQQ"
        required: false
        type: choice
        options:
          - "hybrid"
          - "logreg"
          - "gb"
          - "hgb"
        default: "hybrid"

jobs:
  test-ml-approach:
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: ${{ github.workspace }}
      MPLBACKEND: Agg

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then python -m pip install -r requirements.txt; fi
          if [ -f requirements-dev.txt ]; then python -m pip install -r requirements-dev.txt; fi
          python -m pip install matplotlib scikit-learn pandas numpy joblib

      - name: Backfill Reddit Social Data
        if: ${{ inputs.enable_social }}
        env:
          AE_REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          AE_REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          AE_REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
        run: |
          echo "=================================================="
          echo "Backfilling Reddit Social Data"
          echo "=================================================="
          export AE_BACKFILL_DAYS=${{ inputs.lookback_days }}
          export AE_OFFLINE_DEMO=0
          export AE_REDDIT_SUBS="CryptoCurrency,S&P 500,ethtrader,Solana"
          echo "Fetching $AE_BACKFILL_DAYS days of Reddit data..."
          python -m scripts.social.backfill_social
          echo ""
          echo "Social data backfill complete!"
          if [ -f logs/social_reddit.jsonl ]; then
            echo "✓ logs/social_reddit.jsonl created"
            echo "  Lines: $(wc -l < logs/social_reddit.jsonl)"
            echo "  Size: $(du -h logs/social_reddit.jsonl | cut -f1)"
          else
            echo "⚠ Warning: social_reddit.jsonl not created"
          fi
          echo "=================================================="

      - name: Test Approach 1 - Regime Filtering
        if: ${{ inputs.approach == '1_regime_filter' || inputs.approach == 'all_approaches' }}
        run: |
          echo "=================================================="
          echo "Testing Approach 1: Regime Detection + Filtering"
          echo "=================================================="
          export AE_ML_LOOKBACK_DAYS=${{ inputs.lookback_days }}
          export AE_N_SPLITS=${{ inputs.n_splits }}
          export AE_ML_MODEL_MAP="SPY:${{ inputs.btc_model }},QQQ:${{ inputs.eth_model }}"
          export AE_REGIME_ENABLED=1
          export AE_REGIME_FILTER_ENABLED=1
          export AE_REGIME_VOLATILITY_THRESHOLD=0.06
          export AE_REGIME_TREND_THRESHOLD=0.08
          export AE_ML_SYMBOLS="${{ inputs.symbols }}"
          export AE_SOCIAL_ENABLED=${{ inputs.enable_social && '1' || '0' }}
          export AE_HORIZON_H=${{ inputs.horizon_h }}
          export AE_SOC_SMOOTH=${{ inputs.social_smoothing }}
          export BURST_Z=${{ inputs.burst_threshold }}
          python -m scripts.ml.train_predict
          # Save results with approach name
          if [ -f models/ml_model_manifest.json ]; then
            cp models/ml_model_manifest.json artifacts/approach_1_manifest.json
          fi

      - name: Test Approach 2 - Extended Data
        if: ${{ inputs.approach == '2_extended_data' || inputs.approach == 'all_approaches' }}
        run: |
          echo "=================================================="
          echo "Testing Approach 2: Extended Training Data"
          echo "=================================================="
          export AE_ML_LOOKBACK_DAYS=${{ inputs.lookback_days }}
          export AE_N_SPLITS=${{ inputs.n_splits }}
          export AE_ML_MODEL_MAP="SPY:${{ inputs.btc_model }},QQQ:${{ inputs.eth_model }}"
          export AE_REGIME_ENABLED=0
          export AE_REGIME_FILTER_ENABLED=0
          export AE_ML_SYMBOLS="${{ inputs.symbols }}"
          export AE_SOCIAL_ENABLED=${{ inputs.enable_social && '1' || '0' }}
          export AE_HORIZON_H=${{ inputs.horizon_h }}
          export AE_SOC_SMOOTH=${{ inputs.social_smoothing }}
          export BURST_Z=${{ inputs.burst_threshold }}
          python -m scripts.ml.train_predict
          if [ -f models/ml_model_manifest.json ]; then
            cp models/ml_model_manifest.json artifacts/approach_2_manifest.json
          fi

      - name: Test Approach 3 - Simple LR
        if: ${{ inputs.approach == '3_simple_lr' || inputs.approach == 'all_approaches' }}
        run: |
          echo "=================================================="
          echo "Testing Approach 3: Simplified LR-only Model"
          echo "=================================================="
          export AE_ML_LOOKBACK_DAYS=${{ inputs.lookback_days }}
          export AE_N_SPLITS=${{ inputs.n_splits }}
          export AE_ML_MODEL_MAP="SPY:${{ inputs.btc_model }},QQQ:${{ inputs.eth_model }}"
          export AE_FEATURE_SELECTION=top5
          export AE_REGIME_ENABLED=0
          export AE_REGIME_FILTER_ENABLED=0
          export AE_ML_SYMBOLS="${{ inputs.symbols }}"
          export AE_SOCIAL_ENABLED=${{ inputs.enable_social && '1' || '0' }}
          export AE_HORIZON_H=${{ inputs.horizon_h }}
          export AE_SOC_SMOOTH=${{ inputs.social_smoothing }}
          export BURST_Z=${{ inputs.burst_threshold }}
          python -m scripts.ml.train_predict
          if [ -f models/ml_model_manifest.json ]; then
            cp models/ml_model_manifest.json artifacts/approach_3_manifest.json
          fi

      - name: Test Approach 4 - Per-Regime Models
        if: ${{ inputs.approach == '4_per_regime' || inputs.approach == 'all_approaches' }}
        run: |
          echo "=================================================="
          echo "Testing Approach 4: Per-Regime Models"
          echo "=================================================="
          export AE_ML_LOOKBACK_DAYS=${{ inputs.lookback_days }}
          export AE_N_SPLITS=${{ inputs.n_splits }}
          export AE_ML_MODEL_MAP="SPY:${{ inputs.btc_model }},QQQ:${{ inputs.eth_model }}"
          export AE_REGIME_ENABLED=1
          export AE_PER_REGIME_MODELS=1
          export AE_REGIME_VOLATILITY_THRESHOLD=0.06
          export AE_REGIME_TREND_THRESHOLD=0.08
          export AE_ML_SYMBOLS="${{ inputs.symbols }}"
          export AE_SOCIAL_ENABLED=${{ inputs.enable_social && '1' || '0' }}
          export AE_HORIZON_H=${{ inputs.horizon_h }}
          export AE_SOC_SMOOTH=${{ inputs.social_smoothing }}
          export BURST_Z=${{ inputs.burst_threshold }}
          python -m scripts.ml.train_predict
          if [ -f models/ml_model_manifest.json ]; then
            cp models/ml_model_manifest.json artifacts/approach_4_manifest.json
          fi

      - name: Generate comparison report
        if: ${{ inputs.approach == 'all_approaches' }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          from pathlib import Path

          approaches = {
              "Approach 1: Regime Filtering": "artifacts/approach_1_manifest.json",
              "Approach 2: Extended Data": "artifacts/approach_2_manifest.json",
              "Approach 3: Simple LR": "artifacts/approach_3_manifest.json",
              "Approach 4: Per-Regime Models": "artifacts/approach_4_manifest.json",
          }

          print("\n" + "="*70)
          print("ML IMPROVEMENT APPROACHES - COMPARISON")
          print("="*70 + "\n")

          for name, path in approaches.items():
              p = Path(path)
              if not p.exists():
                  print(f"❌ {name}: No results found")
                  continue

              try:
                  data = json.loads(p.read_text())
                  fold_metrics = data.get("fold_metrics", [])

                  if not fold_metrics:
                      print(f"⚠️  {name}: No fold metrics")
                      continue

                  print(f"✅ {name}")
                  print(f"   Lookback: {data.get('lookback_days', 'N/A')} days")
                  print(f"   Model: {data.get('model_type', 'N/A')}")
                  print(f"   Features: {len(data.get('features', []))}")
                  print(f"   Total folds: {len(fold_metrics)}")

                  # Calculate average pred_mean across folds
                  pred_means = [f.get('pred_mean', 0) for f in fold_metrics]
                  if pred_means:
                      avg_pred = sum(pred_means) / len(pred_means)
                      print(f"   Avg prediction: {avg_pred:.4f}")

                  print()

              except Exception as e:
                  print(f"❌ {name}: Error parsing results - {e}\n")

          print("="*70)
          print("Next step: Check artifacts for detailed results")
          print("="*70)
          PYTHON_SCRIPT

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: ml-improvement-results-${{ inputs.approach }}
          path: |
            artifacts/
            models/ml_model_manifest.json
            models/backtest_summary.json
            models/current/
          retention-days: 30

      - name: Display results summary
        run: |
          echo ""
          echo "=========================================="
          echo "Results Summary"
          echo "=========================================="
          if [ -f models/ml_model_manifest.json ]; then
            echo "✅ Training completed successfully"
            echo ""
            echo "Key files generated:"
            echo "  - models/ml_model_manifest.json"
            echo "  - artifacts/ml_*.png"
            echo "  - models/current/*.joblib"
            echo ""
            echo "Download artifacts to view detailed results:"
            echo "  Actions → This workflow run → Artifacts"
          else
            echo "❌ Training may have failed"
            echo "Check logs above for errors"
          fi
          echo "=========================================="
